// packages/plugin-email/src/utils/bigquery.ts
import { BigQuery } from '@google-cloud/bigquery';
import { Storage } from '@google-cloud/storage';
import { elizaLogger, stringToUuid } from "@elizaos/core";
import type { ExtendedEmailContent } from "../types/email";
import fetchCharacterById from "@elizaos-plugins/plugin-shared-email-sanity";
import constructCharacterPrompt from "@elizaos-plugins/plugin-shared-email-sanity";


const bigquery = new BigQuery();
const storage = new Storage();
const datasetId = process.env.BIGQUERY_DATASET_ID || 'agentvooc_dataset';
const emailsTableId = process.env.BIGQUERY_EMAILS_TABLE || 'emails';
const repliesTableId = process.env.BIGQUERY_REPLIES_TABLE || 'email_replies';
const bucketName = process.env.GCS_BUCKET_NAME || 'agentvooc_email_storage';
const modelEndpoint = process.env.BIGQUERY_MODEL_ENDPOINT || 'bigquery-agentvooc-elizaos.agentvooc_dataset.email_reply_model';

// Initialize dataset
export async function initializeBigQuery() {
  try {
    await bigquery.dataset(datasetId).get({ autoCreate: true });
    
    // Create or replace external object table for GCS (multimodal)
    await bigquery.query(`
      CREATE OR REPLACE EXTERNAL TABLE \`${datasetId}.email_objects\`
      WITH CONNECTION \`bigquery-agentvooc-elizaos.us.agentvooc-connection\`
      OPTIONS (
        object_metadata = 'SIMPLE',
        uris = ['gs://${bucketName}/*']
      )
    `).catch((error: any) => {
      elizaLogger.warn(`Failed to create external table ${datasetId}.email_objects`, { error: error.message });
    });

    elizaLogger.info(`BigQuery initialized for dataset ${datasetId}`);
  } catch (error: any) {
    elizaLogger.error(`Failed to initialize BigQuery`, { error: error.message });
    throw error;
  }
}

// Store email to BigQuery + GCS
export async function storeEmailToBigQuery(mail: ExtendedEmailContent, userId: string) {
  try {
    elizaLogger.info(`[BIGQUERY] Storing email`, { messageId: mail.messageId, subject: mail.subject });
    const bodyFilePath = `${encodeURIComponent(mail.messageId || mail.emailUUID || `email-${Date.now()}`)}/body.txt`;
    const gcsBodyUri = `gs://${bucketName}/${bodyFilePath}`;
    const bodyContent = mail.text || 'No content';

    // Save body to GCS
    const bodyBlob = storage.bucket(bucketName).file(bodyFilePath);
    await bodyBlob.save(bodyContent, { contentType: 'text/plain', metadata: { cacheControl: 'no-cache' } });
    elizaLogger.info(`[BIGQUERY] Stored email body in GCS`, { gcsBodyUri, bodyLength: bodyContent.length });

    // Save metadata to BigQuery
    const timestamp = mail.date && !isNaN(new Date(mail.date).getTime())
      ? new Date(mail.date).toISOString()
      : new Date().toISOString();
    const row = {
      id: mail.emailUUID,
      user_id: userId,
      from_address: mail.from?.[0]?.address || '',
      subject: mail.subject || '',
      body: bodyContent,
      timestamp,
      message_id: mail.messageId,
      thread_id: mail.threadId,
      references: mail.references || [],
      gcs_body_uri: gcsBodyUri,
      gcs_attachments: [],
    };
    await bigquery.dataset(datasetId).table(emailsTableId).insert([row]);
    elizaLogger.info(`[BIGQUERY] Stored email metadata in BigQuery`, { id: mail.emailUUID, timestamp });
  } catch (error: any) {
    elizaLogger.error(`[BIGQUERY] Failed to store email`, { error: error.message, emailUUID: mail.emailUUID });
    throw error;
  }
}

// Fetch email body from GCS
export async function getEmailBody(gcsUri: string): Promise<string> {
  try {
    const filePath = gcsUri.replace(`gs://${bucketName}/`, '');
    const [content] = await storage.bucket(bucketName).file(filePath).download();
    const body = content.toString('utf-8');
    elizaLogger.debug(`[BIGQUERY] Fetched email body from GCS`, { gcsUri, bodyLength: body.length });
    return body || 'No content available';
  } catch (error: any) {
    elizaLogger.warn(`[BIGQUERY] Failed to fetch email body from GCS`, { gcsUri, error: error.message });
    return 'No content available';
  }
}

// Generate reply using ML.GENERATE_TEXT
// Generate reply using ML.GENERATE_TEXT with character context
export async function generateReplyWithBigQuery(emailId: string, promptContext: string, agentId: string) {
  try {
    // Fetch character data from shared utility
    const character = await fetchCharacterById(agentId);
    if (!character) {
      elizaLogger.warn(`[BIGQUERY] Character not found for agentId: ${agentId}`);
      throw new Error(`Character not found for agentId: ${agentId}`);
    }

    // Construct character-specific prompt using shared utility
    const characterPrompt = constructCharacterPrompt(character, promptContext);

    const query = `
      SELECT ml_generate_text_result AS reply_body, 'Re: ' || subject AS reply_subject
      FROM ML.GENERATE_TEXT(
        MODEL \`${modelEndpoint}\`,
        (
          SELECT @prompt AS prompt, @emailId AS original_email_id, subject
          FROM \`${datasetId}.${emailsTableId}\`
          WHERE id = @emailId
          LIMIT 1
        ),
        STRUCT(
          0.8 AS temperature,
          512 AS max_output_tokens
        )
      )
    `;
    const options = {
      query,
      params: { prompt: characterPrompt, emailId },
    };
    const [job] = await bigquery.createQueryJob(options);
    const [rows] = await job.getQueryResults();
    const result = rows[0] || { reply_subject: 'Re: Original Subject', reply_body: 'Thank you for your email. I will get back to you soon.' };
    
    elizaLogger.info(`[BIGQUERY] Generated reply for email ${emailId}`, { reply_subject: result.reply_subject, reply_body_length: result.reply_body.length });
    return result;
  } catch (error: any) {
    elizaLogger.error(`[BIGQUERY] Failed to generate reply with BigQuery`, { error: error.message, emailId });
    return { reply_subject: 'Re: Original Subject', reply_body: 'Thank you for your email. I will get back to you soon.' };
  }
}

// Fetch recent emails
export async function fetchRecentEmails(userId: string, limit: number = 50) {
  try {
    const query = `
      SELECT * FROM \`${datasetId}.${emailsTableId}\`
      WHERE user_id = @userId
      ORDER BY timestamp DESC
      LIMIT @limit
    `;
    const options = {
      query,
      params: { userId, limit },
    };
    const [job] = await bigquery.createQueryJob(options);
    const [rows] = await job.getQueryResults();
    return rows;
  } catch (error: any) {
    elizaLogger.error(`Failed to fetch recent emails`, { error: error.message });
    return [];
  }
}

// Store sent reply
export async function storeReplyToBigQuery(originalEmailId: string, reply: { subject: string, body: string }, success: boolean) {
  try {
    const row = {
      id: stringToUuid(`${originalEmailId}-reply-${Date.now()}`),
      original_email_id: originalEmailId,
      reply_subject: reply.subject,
      reply_body: reply.body,
      timestamp: new Date().toISOString(),
      sent_success: success,
    };
    await bigquery.dataset(datasetId).table(repliesTableId).insert([row]);
    elizaLogger.debug(`Stored reply in BigQuery`, { id: row.id });
  } catch (error: any) {
    elizaLogger.error(`Failed to store reply`, { error: error.message });
    throw error;
  }
}

// Generate embedding for an email
export async function generateEmailEmbedding(emailId: string) {
  try {
    const query = `
      INSERT INTO \`${datasetId}.email_embeddings\` (email_id, body, embedding, created_at)
      SELECT
        id AS email_id,
        content,  -- Changed from 'body' to 'content'
        ml_generate_embedding_result AS embedding,
        CURRENT_TIMESTAMP() AS created_at
      FROM ML.GENERATE_EMBEDDING(
        MODEL \`${datasetId}.embedding_model\`,
        (
          SELECT id, body AS content
          FROM \`${datasetId}.${emailsTableId}\`
          WHERE id = @emailId
        )
      )
    `;
    const options = { query, params: { emailId } };
    await bigquery.query(options);
    elizaLogger.info(`[BIGQUERY] Generated embedding`, { emailId });
  } catch (error: any) {
    elizaLogger.error(`[BIGQUERY] Failed to generate embedding`, { error: error.message, emailId });
    throw error;
  }
}

// Find similar emails using vector search
export async function findSimilarEmails(emailId: string, topK: number = 5) {
  try {
    const query = `
      WITH query_embedding AS (
        SELECT embedding
        FROM \`${datasetId}.email_embeddings\`
        WHERE email_id = @emailId
      )
      SELECT
        base.email_id,
        base.body,
        DISTANCE(query_embedding.embedding, base.embedding, 'COSINE') AS distance
      FROM \`${datasetId}.email_embeddings\` base, query_embedding
      WHERE base.email_id != @emailId
      ORDER BY distance
      LIMIT @topK
    `;
    const options = { query, params: { emailId, topK } };
    const [job] = await bigquery.createQueryJob(options);
    const [rows] = await job.getQueryResults();
    elizaLogger.info(`[BIGQUERY] Found similar emails`, { emailId, count: rows.length });
    return rows;
  } catch (error: any) {
    elizaLogger.error(`[BIGQUERY] Failed to find similar emails`, { error: error.message, emailId });
    return [];
  }
}